-
    name: undefined
    mail: ''
    subject: 'certs haven''t caught on, why this?'
    hostname: 192.31.106.34
    created: '1178154459'
    body: "HTTP sessions can right now be encrypted and authenticated using TLS (or SSL), but nobody i know does it (here in the US).  and i'm not talking about authenticating the server, but the client.\r\n\r\n<cite>SSL is used for this, but for the whole certificates process to work you need one public IP per virtual host.</cite>\r\n\r\nTLS requires a unique IP address?  no; a unique endpoint (IP and port) is sufficient.  isn't specifying something other than port 80 too difficult for users?  it's easier than generating and properly handling a public-private key pair.  and people just go to their bank's home page and find the redirecting form (bad!) or link for login to the \"secure\" web site, so why can't that be replaced with a link that has a port number in the url?  and for most businesses willing to go through the expense of client-side auth (TLS, PGP, etc), a dedicated IP address is nothing.\r\n\r\n<cite>Enigform works on the application layer, not at socket layer, it can even work behind accelerators, reverse proxies, etc.</cite>\r\n\r\nyes, because SSL does encryption at the transport layer the application layer is obscured, so there's less flexibility (you can only play games at the transport layer, not the application layer).  but usually the main concern is load balancing which is possible if you distribute connections based on TLS sessions and share the same cert across all web servers.  it may even be possible in practice to just distribute TCP streams, ignoring TLS sessions.\r\n\r\n<cite>the high cost of SSL certificates</cite>\r\n\r\nyes, if you want 3rd party verification, you need to use a recognized certificate authority, but there's nothing to stop a bank from becoming their own authority.  and certificate authorities are not even necessary if the trustworthiness of the certificate was established out-of-band (eg in person at bank branch office, by physical mail, etc).  certificate authorities are only so by trusting a single entity you can implicitly trust all issued certificates (without verification of each individual certificate), but as long as my bank trusts my cert (by verifying it ahead of time), it accomplishes the same.  and PGP's partial/accumulative trust might work for social networks, but i don't see it as beneficial/necessary for banks that want me to sign on the dotted line, not 2 or 3 people they trust to know me.\r\n\r\n<cite>we could also talk about the cryptographic benefits of using the algorithms and keysizes an OpenPGP implementation allows</cite>\r\n\r\nplease elaborate on what cryptographic benefits PGP has over TLS, as GPG and OpenSSL, common implementations of each standard, support the widely used RSA and AES algorithms in 2048 & 256 bit keysizes, respectively.  TLS is currently limited to MD5 & SHA1, the two most popular hashes, but both TLS & OpenPGP (RFC 2440) lack SHA2 (though draft RFCs addressing SHA2 exist for both).  yes, OpenPGP allows for less popular algorithms, but i don't see that as a big cryptographic advantage (as \"less popular\" means \"less analyzed\").\r\n\r\nand there is a draft for using OpenPGP keys for TLS but who knows if it will go anywhere.\r\n\r\nHTTP-PGP would allow for more granular use of encryption/authentication in HTTP than TLS, but securing the entire transport seems good enough.  MIME supports the fine granularity of mixing OpenPGP and plain texts in the same email message, but i haven't seen an email application do that but instead just apply OpenPGP to the entire email; probably because securing the entire email is \"good enough\".\r\n\r\nis HTTP-PGP complimentary and/or supplimentary to TLS and are choices important?  yes.  has TLS been widely adopted for client-side auth and does HTTP-PGP have any more chance of being used?  no.\r\n\r\ni just don't see any attribute of HTTP-PGP being so much better than TLS that it sees more uptake than TLS."
-
    name: 'Anonymous visitor'
    mail: jovenzuelo@gmail.com
    subject: 'well, from the interview,'
    hostname: 190.49.69.167
    created: '1178291877'
    body: "well, from the interview, i'd say it's just an alternative to ssl/tls but only in some aspects and in some environments.\r\n\r\nhaving alternatives is good, and one using OpenPGP looks just fine.  in any case, installing enigform (yeah,i tried it, why commenting if you haven't tried it, anyway) in  is painless, and configuring mod auth pgp on apache is quite easy, too.\r\n\r\ni think the best benefit is that it allows to avoid the concept of \"login\". for the sake of testing, i wrote a simple web site, i added the public keys of some test users to the keyring at the server. they didn't have to login, just get to the site, and they were automagically logged-on, identified by their keyid, fingerprint or email address.\r\n\r\nyeah i liked it, i'm waiting for mod_auth_openpgp to grow some more (having auto public-key importing would be cool,and a management interface via a sethandler!).\r\n\r\n"
-
    name: 'Anonymous visitor'
    mail: supraexpress@globaleyes.net
    subject: 'Possible fundamental advantage to Enigform'
    hostname: 209.131.253.73
    created: '1182497948'
    body: "GnuPG provides for \"digital signatures\", as well as other things. Digital signatures provide for \"authentication\" and \"integrity\". Leaving aside discussions of SSL/TLS/GnuPG encryption and \"single-sign-on\", another use for GnuPG is the production of a digital signature for any given \"message\". This is one function that TLS/SSL don't make use of today, as far as I know.\r\n\r\nThe possible ability to apply and recover message authentication and integrity would itself be a big boon in many applications, even without considering \"web of trust\" issues with GnuPG/PGP \"keys\"."
-
    name: undefined
    mail: ''
    subject: 'see RFC 2246'
    hostname: 68.94.189.15
    created: '1182745000'
    body: "you don't even have to get into the technical details of RFC 2246 to know that TLS provides authentication and integrity checking.\r\n\r\nfrom the abstract:\r\n<cite>The protocol allows client/server applications to communicate in a way that is designed to prevent eavesdropping, <strong>tampering</strong>, or <strong>message forgery</strong>.</cite>\r\n\r\nfrom the introduction:\r\n<cite>The primary goal of the TLS Protocol is to provide privacy and <strong>data integrity</strong> between two communicating applications.</cite>\r\n\r\ncontinue reading the RFC to learn the details, but to summarize:\r\n<ul>\r\n<li>\"TLS Record Protocol\" provides the integrity checking by way of MACs (MD5 or SHA)</li>\r\n<li>\"TLS Handshake Protocol\" provides authentication by way of public keys (RSA or DSS)</li>\r\n</ul>\r\n\r\nTLS even has a \"null\" cipher which should approximate OpenPGP signed cleartext.  to see it in action:\r\n<ol>\r\n<li><code>openssl s_server -cert server.pem -accept 65000 -cipher eNULL</code>\r\n<li><code>openssl s_client -connect localhost:65000 -cipher eNULL</code>\r\n<li><code>sudo wireshark</code>\r\n</ol>\r\n\r\nnote: you'll want to instruct wireshark to decode the transport as SSL as port 65000 is not associated with SSL/TLS.\r\n\r\nfinding a \"real world\" implementation might be difficult (or at least configuring it) because i've never seen TLS used without encryption.  the default OpenSSL cipher list excludes NULL.  and most (all?) deployments exclude the NULL cipher because there have been downgrade attacks where a man-in-the-middle could force a weak cipher so the stream could be easily decrypted.\r\n\r\nand the common usage of OpenPGP cleartext signatures is for a message going to an unknown recipient (or a recipient with an unknown key), usually for wide distribution (mailing lists, software downloads, etc).  that use case is impossible for TLS because the communication is real-time (where the key can be learned and validated in real-time using certificate authorities) with a single endpoint.\r\n\r\noverall OpenPGP and TLS use the same algorithms (AES, 3DES, MD5, SHA, RSA, DSS/DSA) for the same purpose (encryption, integrity, authentication).  though there are slight protocol/implementation differences, i don't believe any are significant enough to garner Enigform more widespread adoption than TLS for client-side authentication.\r\n\r\n(I want to be proven wrong by seeing widespread use of encryption and authentication, whether in the form of Enigform or TLS.)"
-
    name: pivo
    mail: pivo@pobox.sk
    subject: 'As you state earlier, I'
    hostname: 89.173.72.212
    created: '1187981130'
    body: 'As you state earlier, I think the advantage of this approach is its granularity. My server would encrypt only the content that needs to be encrypted and the rest would be signed and thus at the same time unforgeable and cachable both on the client and any intermediate proxies. This is not currently possible as far as I know. Otherwise, please enlighten me.'
-
    name: undefined
    mail: ''
    subject: 'http enigform granularity analysis'
    hostname: 68.93.98.201
    created: '1188020160'
    body: "based on this article's description of enigform and a quick perusing of <a href='http://freshmeat.net/articles/view/2599/'>Busleiman's freshmeat article</a>, i ascertain that engiform can encrypt a single request or response (in theory), where TLS always encrypts both (at least in practice and probably also in theory unless mid-stream renegotiation exists as in some other protocols).\r\n\r\nhere's a supporting quote from this article:\r\n<cite>Enigform does not break HTTP in any way, it just adds a set of request headers.</cite>\r\n\r\nand from the freshmeat article:\r\n<cite>There was no more HTTP POST body tampering, just a set of HTTP headers added to each request: The signature itself, a GnuPG version string, and a Digest Algorithm string.</cite>\r\n\r\ni didn't see enigform encryption elaborated on, but i presume it works in a similar fashion to signing: encryption metadata in headers with the body encrypted, possibly as a new content type (requiring a new Content-Type header).\r\n\r\ntechnically, TLS encrypts per TCP connection, not HTTP request/reply (as it operates on the transport layer, not the application layer), but you can send all encrypted requests/replies over one TCP connection, and unencrypted requests/replies over another TCP connection (eg web page contents over https, but generic images over http).  your password could be submitted over an encrypted TCP connection where the server's response would redirect you to an unencrypted web site.  (logging in with a password wouldn't even be necessary with client-side certs, but you get the idea.)\r\n\r\nenigform can conceivably encrypt only half of a request/reply pair (user sends password in encrypted request while server responds with unencrypted reply), where with TLS both request & reply are either encrypted or unencrypted as the reply must be sent over the same TCP connection as the request.  so there's a little bit more flexibility with enigform.\r\n\r\ncurrently web browsers notify the user about web pages with mixed encrypted/unencrypted content (TLS encrypted & unencrypted TCP connections on same page), but there's no technical reason that warning can't be removed if mixed content becomes the accepted practice (because what i want to be warned about is unencrypted data submitted from an encrypted page, as a user would general assume an encrypted page would submit encrypted data).\r\n\r\ni wonder what variety of attacks are possible against enigform as it appears enigform only safeguards HTTP contents, but not headers (at least in the example of signatures in the freshmeat artcle, but i suppose encryption works the same).  can cookies not be authenticated or encrypted using enigform?  and are urls visible, compared to TLS where the entire connection (headers & body) is encrypted, protecting even the url requested (ie information disclosure)?\r\n\r\nagain, please don't interpret my critique as disapproval of enigform, except in the fact that enigform is so similar to TLS from a practical standpoint that i see no reason why it should succeed where TLS has failed (and failed not for technical reasons necessarily, but maybe because everybody thinks passwords are sufficient for client-side auth)."
-
    name: undefined
    mail: ''
    subject: 'addition: SSL hostname-based solution exists'
    hostname: 68.93.98.201
    created: '1188020950'
    body: "this removes one of the limitations of TLS.\r\n\r\n<a href='http://www.g-loaded.eu/2007/08/10/ssl-enabled-name-based-apache-virtual-hosts-with-mod_gnutls/'>instructions</a> to implement SNI (server name indication) in an apache installation, which allows multiple server certs (one for each hostname or virtual server) per TCP endpoint (ip address & port).\r\n\r\nfound by way of <a href='http://blog.thedebianuser.org/?p=196'>this blog</a>"
-
    name: pivo
    mail: pivo@pobox.sk
    subject: 'caching signed content'
    hostname: 89.173.72.212
    created: '1188420900'
    body: "I mostly agree with you.\r\n\r\nBut currently no http scheme that allows a server to sign the content and make it cachable by proxies. If done right, that'd be a killer feature. As you also note, some of the headers would have to be covered by the signature as well.\r\n\r\nThe creator of enigmail has this to say about the issue (from freshmeat):\r\n\"As you saw, I decided to focus on Identity and Data authentication of client at server, but of course I'm also thinking about the same scheme in reverse.\"\r\n\r\nAnd the creators of coralcdn also saw a need for server signatures, as on http://wiki.coralcdn.org/wiki.php?n=Main.FAQ#rewrite I found this: \"To handle\r\nthis issue, we've written an apache module that servers can use to sign content\r\nto ensure content integrity and freshness, to be verified both and proxies and\r\npossibly by client browser extensions.\"\r\n\r\nBut so far I haven't got any response to my request for clarification on their mailing list: http://www.cs.nyu.edu/pipermail/coral-users/2007-August/000511.html"
-
    name: undefined
    mail: ''
    subject: 'stupid me: yes, cachable authentication'
    hostname: 68.93.98.201
    created: '1188445424'
    body: "i totally missed that in your first post.  yes, server-signed content would be cachable (in theory; i don't know how caching proxies, like squid, handle headers and if they are maintained with the associated cached content).\r\n\r\nmy guess is that currently headers are not signed nor encrypted because of the difficulty in implementing it in a standards-compatible way (ie assuming the signature headers apply to all headers that follow them, can it be guaranteed that a proxy server won't add any of its own headers below the signature headers or reorder the headers, ruining the signature).\r\n\r\nand i can see the benefit for public web servers that want to serve signed content (linux distros: security bulletins, installation instructions, etc) but also need it to be cached for web site performance.\r\n\r\nbut when i want encryption, i want everything encrypted (no information disclosure even through headers, especially the request header which would be difficult to encrypt and not break standards).\r\n\r\nso i can see how enigform would excel at authentication (or minimal encryption use like only submitting a password on a login form) while ssl would be reserved for encryption (banking web site)."
