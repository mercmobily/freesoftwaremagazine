-
    name: WoundedChin
    mail: bing@zork.de
    subject: 'Brilliant Idea! With this'
    hostname: 193.198.144.104
    created: '1181066904'
    body: 'Brilliant Idea! With this you could re-arrange a computer into a media player, then arrange it back again. You''ve stumbled onto something big. I hope the hardware makers are reading this.'
-
    name: 'Dave Guard'
    mail: ''
    subject: 'I imagine them looking like CD racks'
    hostname: 165.98.157.37
    created: '1181092870'
    body: "Great idea Matthew and well thought out. \r\n\r\nI can picture these PCs looking like CD/DVD racks - each component slotting into the rack and taking up one or more slots. No need for cables. How easy would the hot-swapping of components be if you just have to push-and-pop each one in/out? If you run out of room you buy a bigger rack.\r\n\r\nI'm sure I've seen some sort of prototype or mock-up of this idea somewhere but they used books on a shelf rather than CDs in a rack.\r\n"
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Asus Modular PC'
    hostname: 82.153.26.195
    created: '1181120649'
    body: "Found this link regarding the Asus Modular PC, possibly the mock-up you were thinking of?\r\n\r\nhttp://www.reghardware.co.uk/2006/02/23/asus_concept_shelf_pc/\r\n\r\n*Very* similar to what I've described in the article (and nice to find something backing up what I've written, I'm getting kinda excited now :)).  Though still in the concept stage the idea of powering the devices by induction from the shelf is brilliant, though I have to admit I personally don't like the bookshelf layout (but admit again I can't think of anything better atm).  Pure wireless connectivity (as opposed to a combination of wired and wireless which I assumed), though very conducive to usability, was something I discounted for the immediate future due to latency and bandwidth (I wanna play games on one of these things!), but is something I'd love to see just to get rid of those damn cables :)\r\n\r\nI'm currently writing a follow-up on exactly how the components of a modular system could work together with a heavy slant on simplicity (and using open source  components)."
-
    name: 'Taavi LÃµoke'
    mail: starfish2@gmail.com
    subject: 'That is a really great idea,'
    hostname: 194.204.22.25
    created: '1181125222'
    body: "That is a really great idea, but I think that there are some problems.\r\n\r\nThe idea, that indexing service could be integrated into the storage box, seems to be a good one at first. At closer examination it revealed a weak point. I imagine there would be a communication protocol that regulates how to talk to storage devices. At first it probably wouldn't include indexing services specific commands, but when a storage box integrates such a service it would still need drivers to provide new commands over the old standard. Finally the protocol probably would be updated to facilitate those kinds of commands, but every time something new is implemented drivers would still be needed. So it is kind of the same as at the moment. What do you think, is there a way to relieve that problem?\r\n\r\nAnother thing: i have nothing against Linux, but reading the article this Linux evangelism was just a bit annoying. This kind of articles should be written without preferring any present operating systems as this system would probably need a new kind of software anyway."
-
    name: 'Tiffany Rice'
    mail: zac.toff@ntlworld.com
    subject: Brilliant
    hostname: 81.157.220.22
    created: '1181125432'
    body: "What a fantastic idea, the modules could be designed by different artists to make an artistic display, either just nicely colour or with different images/patterns to make your PC a work of art as well as one of genius.\r\n\r\nThis idea should definitely be invested in by a major player. Lets hope the developer gets his fair share."
-
    name: 'Ron Phillips'
    mail: ''
    subject: 'Optical network'
    hostname: 70.61.233.130
    created: '1181132340'
    body: "It would be nice if the component computers could communicate optically. It avoids a lot of EMI problems, and the bandwidth ought to be sufficient for almost anything.\r\n"
-
    name: 'Dave Guard'
    mail: ''
    subject: 'That''s the one'
    hostname: 165.98.157.37
    created: '1181157505'
    body: 'That''s definitely where I saw it. The CD rack picture I have in my mind is prettier than their shelf design. I can also imagine people providing skins for the individual units so you can "theme" your machine.'
-
    name: Benedictarf
    mail: benedict1000@yahoo.co.uk
    subject: 'Parts already exist (sort of)'
    hostname: 82.46.26.79
    created: '1181208598'
    body: "I was thinking about this and couldn't get past the problem of cost and explaining the concept to your average Joe:\r\n\r\n\"So I have to buy a new computer if I want to open my email?\"\r\n\r\nBut then I realised that parts for this system already exist, namely the iPod. It works by its self and I'm sure it would only take a firmware update to make it in to soundcard with usb(or what ever protocol takes your fancy) connectivity. There must be simmilar consumer devices.\r\n\r\nI think a good analogy for the system is the Power Ranger (bare with me). Seperatly they all have their own skills, but put them together and they make a giant that's greater than the sum of its parts."
-
    name: 'Matthew Roley'
    mail: ''
    subject: ':o)'
    hostname: 82.153.26.195
    created: '1181220457'
    body: 'Hehe, turns out this is one of my friends.  The point is a great one though, for many people the visual look of the system will be very important, and would give manufacturers the opportunity to produce a ''suite'' of devices unified in aesthetic, while allowing the pragmatists to stick with a bunch of grey bricks.'
-
    name: 'Matthew Roley'
    mail: ''
    subject: Agree
    hostname: 82.153.26.195
    created: '1181222849'
    body: 'Yeah this is something definitely worth considering.  I''m not absolutely certain at this point whether it would be best to just define a protocol and let market forces (and performance requirements) determine the best connectivity options; or set a connectivity standard from the start (which would make things a lot easier *if* device manufacturers could be convinced).  Though I''m a bit wary of telling people what to use (the whole point of this system is that people can use the hardware and software they want) I sort of lean toward the latter.  The interoperability of the devices over the ''network'' is so important that perhaps it should be set ''in stone''.  Optical would be right up there in a list of candidates for this, but there also definitely a need for wireless connectivity there too.  Bandwidth is a very important consideration (particularly for the way I anticipate graphical data moving around the system) but there''s also the issues of cabling, latency (I''m not sure about the numbers for optical networks, but I imagine they''re pretty good) and also aesthetic appeal.'
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Absolutely but...'
    hostname: 82.153.26.195
    created: '1181223224'
    body: "The parts do already exist, you're absolutely right.  And putting them together does result in a gestalt system.  But this is no different from a current PC.  All the same parts will need to be bought (optical drives, graphics cards, sound card, network card (for interfacing to any networks 'external' to the system network) as they are in a current PC, and they all add capability to the system (again, as with a current PC), where this system improves on the first is they should be a lot easier to manage and a lot more stable because of their isolation (interaction over a unified well defined 'network') and their 'intelligence' (because they'll generally have their own processing and storage resources making them more adaptable than a 'standard' device.  The other advantages are you can keep on adding devices, certainly far more than achievable on a standard PC, and having a standard communication protocol means integrating new kinds of devices should be easier as the main compatibility target to aim for is support for whatever network standard is decided upon (theoretically you could add a quantum processing box transparently to this system when the technology becomes a reality, upgrading a PC of today would involve scrapping much of your current system).  These advantages do come at a price though, because of the price overhead for having processing and storage resources in the device.  I think I say in the article this could be offset somewhat by a cheaper development process for the device, if not I've just said it now.\r\n\r\nThe Power Ranger analogy is a good one, you could probably even build one of these systems to look like one (storage devices for arms, the kernel and application boxes as the body and a webcam for a head :o)  \r\n\r\n"
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Thanks for the comments so far'
    hostname: 82.153.26.195
    created: '1181224611'
    body: 'Thanks to everyone who''ve posted (and those who may post).  Gonna get back to work and will continue writing the followup for anyone who is interested.  I''ll check back on any comments and incorporate them into my article if possible, but won''t be replying to anymore unless they''re really pertinent (or a follow up to any questions I''ve answered above).  As you may notice I have a tendency for long expanses of text and I don''t want to spend the next three years writing replies :o)'
-
    name: 'John Sargeant'
    mail: js@jsarge.com
    subject: 'Forgive me if I''m wrong,'
    hostname: 87.194.99.173
    created: '1181226563'
    body: 'and I think I speak for everyone here in saying that I don''t see how having a dishwasher plugged in to my xbox 390 or whatever it is in the future is going to help anyone at all. It''s science fact turned in to science fiction!!!!'
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Not a problem'
    hostname: 82.153.26.195
    created: '1181226869'
    body: "While this is a very important question that needs to be answered early in the design of such a system, I believe it is a non-issue.  Think of the way the HTTP protocol works in conjunction with a browser and a server.  This protocol, while it's been extended a bit over the years has remained pretty stable.  All the user does (via the browser, or even the command line) is request a resource with a unique  id (it's Uniform Resource Name, which covers the protocol used, http or ftp for example, as well as it's location, the host, and finally the requested resource).  When you make such a request, your browser identifies the host for the resource (through DNS) then makes a connection to the host  (through whatever protocol identified in the URN) requesting the resource.  From the point of view of the browser it doesn't matter *how* the server provides that resource, it will either get the data in the expected format (e.g. HTML) or it will get an HTTP error code.  From the point of view of the server; it gets requests for resources which it either honors or returns an error for (or is timed out on the browser or server side).  Now the server is a black box, the resource requested could be a static file, a virtual file or even a proxy request to another server.  That image your browser requested could just be a static .png or generated from a script, it doesn't matter to the browser, all it gets is what it asked for.  Well run web servers update their internal configuration all the time, particularly as their userbase increases, updating their version of apache (or IIS), changing from sqllite to mysql (or from Access to SQLServer), adding an indexing daemon, even splitting into a cluster; the list of things that can be done internally to a webserver are endless, and the point is (aside from downtime and potential bugs) these changes have no impact on the end user (browser).  Things may be going on differently behind the scene but the browser makes requests in the same way and gets what it asks for.  And note specifically that NO change to the HTTP protocol is required, even though the services and data offered by the webserver may have changed.\r\n\r\nExtending the web analogy to the distributed system; i imagine all the devices in the system acting as servers (and clients) with the 'kernel box' in my article acting in a way similar to a dns server (in that it routes requests for a resource to the proper device or application; but looking like a file system, in that instead of domain names you'd have a (virtual) file (e.g. /dev/storagebox), all requests for files to /dev/storagebox (e.g. /dev/storagebox/myfile) would be processed by the relevant device (or application), in the case the storage box would receive a request for /myfile which it can process internally any way it wants.  A shorter way of saying this is it would probably work in a manner similar to NFS, but with optimisations for the fact the the network is very fast and very local.  Management and configuration on the device (such as an indexing service) can be handled in the same way (continuing the web analogy you have things like webmin which serve exactly this kind of function).  \r\n\r\nOn the issue of updating the drivers for the device.  Of course there will be software updates required for the devices.  Security fixes, performance updates, feature changes are all facts of life in the software world and they won't disappear whatever system you're using.  Where this kind of system really scores though is that updates to the device <cite>do not impact or interact with the rest of the system</cite>.  The updates are internal to the device and cannot affect the rest of the system (except indirectly in what the device offers to the system) in the same way a driver update might (like say, clobbering a file; or a buggy interaction with the kernel).  Fundamentally a storage box on this system would work like any NAS (network attached storage) device available today, even in the home market (see http://en.wikipedia.org/wiki/Network-attached_storage).  Updating these devices is a doddle as the update consists of a single image file (containing whatever is going to be running on the device, including operating system and software) that is flashed straight onto the device.  So the device can be suspended from the system (not serve any requests temporarily), flashed then reinstated without having to power down or reboot the entire system.  Backup up images also mean a rollback in case of problems is trivial, these backup images could be stored elsewhere on the system and/or in a hidden partition of the device (the way many hardware providers provide rescue solutions for home systems now).\r\n\r\nThe real software issues to solve on such a system boil down to parallelism, such as co-ordinating timing of audio output (on an audio device) with video output (to the screen) when playing say, a video stream.  This of course would be a nightmare  if the data were moving over a network with high variable latency (such as the internet), but the fact that much of the work is local on a high-speed, low-latency network (essential for such a system) means in my mind that they are solvable in software.  Deadlock and general contention issues must also be resolved, though the theory and implementation of those doesn't really differ that much from current multi-threaded/multi-processor/multi-core systems.\r\n\r\nOn the issue of Linux evangelism.  I'm sorry if my article came across this way, I'm pretty adamant that device manufacturers (including users who build their own devices) should have free choice in what they use to implement the device, whether they choose free software or proprietary should be irrelevant to the system, and will really only affect how they build their device and the costing of their device.  This system would never work if vendors were forced down a particular route in their implementation.  I'd love to see XBox 360s, washing machines, *any* kind of device working in this system, and the only requirement on those system to participate should be the ability to talk over the protocol (and appropriate connectivity, either directly or through an adapter).  This doesn't exclude other systems, in fact it welcomes them.  The reason my article states 'the answer lies (mostly) with GNU/Linux' boils down to the following facts.\r\n\r\n-- Linux runs on more architectures than any other operating system.  This greatly opens up the implementation choices for vendors, and is the reason why so many consumer devices run Linux internally.\r\n\r\n-- The Linux kernel is free as in beer.  Many manufacturers already exploit this fact to build cheaper devices.  I don't personally have much in the way of cash so if I was knocking something together I'd pretty much *have* to use Linux.\r\n\r\n-- The Linux kernel is free as in speech.  Source code is available and can be modified for purpose.  Essential when building specialised devices, you can take the source code and start from there.  Also essential for home hackers building their own devices, if you can't get working source code for your device you aren't gonna get past the first bend.\r\n\r\n-- The Linux Kernel marches on.  The kernel is constantly being improved with newer versions, but the older version continue to have patches supplied for fixes and improvements, thanks to the open-source community.  Proprietary systems generally don't offer this level of support for 'obsolete' versions of their software (as is now happening with Windows XP).  This is necessary for a distributed system because a device manufacturer may incorporate a particular kernel version into their device.  This version of the kernel may never need to be  updated for the device as it may not need the features offered by newer versions (which would simply add bloat and work for the device manufacturer); however, bugs can and do appear and they will need to be fixed, it's a hell of a lot easier to achieve this if you're running a Linux kernel on the device.\r\n\r\nThese factors would simply make Linux a great choice for many device makers (as it is now) but it does not in any way prevent the use of other operating systems (as my article says) and would likely result in most of the devices in the system running Linux (hence, mostly linux) but wouldn't exclude any architecture or device operating system from the party.  In fact there's no reason at all why the kernel box of a user's system couldn't run embedded windows; as long as the 'implementors' don't make subtle changes to how the overall system works to ensure broken interoperability (ok, i'm being a bit bitchy there).  Take a look at http://www.windowsfordevices.com/ to see that windows does just fine in the area of devices, also check http://www.linuxdevices.com to see the Linux powered counterparts.  More important than any of those factors above is the absolute necessity that this system is completely open and not controlled in a proprietary way by a single company; it should be a free and easy standard to implement by anyone.  The 'system' wouldn't really be Linux (or any other os for that matter), it's really no more than a software layer for connecting devices (with their own internal operating systems) in a well-defined way and possibly over well-defined transport mechanism(s).\r\n\r\nYou've sort of made me jump the gun a bit, I am currently writing a followup that goes into more detail on this; but that could be a good thing in a way.  What I'm essentially hoping for by writing this stuff is that enthusiasts and the big brains out there will embrace this idea (at least in principle) and come up with a cracking protocol that works and works well.  In terms of Linux the kernel and current software are there to be used, and i'm sure at least a proof of concept prototype could be cobbled together with a bit of work.  I have my own ideas and a relatively broad knowledge base (bit shallow in places :o) but I'm just one guy and there are many ways this system could be built; and as you say with the possible requirement of a new programming model a definite possibility it's best to get a lot of input on how willing people are to work on this.\r\n\r\nPhew, quite a long post, hope it actually answers your questions!  Thanks for your input and congratulations, you're one of the first contributors to the cause!"
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'John Sargeant we meet again!'
    hostname: 82.153.26.195
    created: '1181237661'
    body: 'Get back to trolling on the flash and knight-rider forums my friend, this is not the place for your hi-jinks :o)'
-
    name: tinker
    mail: ''
    subject: 'I am already doing this, in'
    hostname: 213.169.107.71
    created: '1181554310'
    body: "I am already doing this, in a much more inelegant way, with a handful of old conventional PC's. The boxes are, for the most part, hidden away, the central heating control box is hidden in the heating cupboard and linked with CAT5 cable, the printer and scanner box is also in that cupboard while the scanner and printer usb cables pass through ducts to the office above.  I have 6 other old boxes doing specialist jobs but all out of sight, and 2 main new boxes as workstations for doing 'stuff' and where I can check/alter the other 8 systems from. \r\n\r\nAs I have not used winblows for years I am not sure if the system would work in an M$ enviroment, especially the older and smaller boxes. Linux is, in my case, the most obvious choice currently though I will admit that something new, not yet thought of perhaps, may be even better at integrating such a system.\r\n\r\nIdeally all these boxes would become like the small modules you talk about and actually be part of the fabric of the house with a plasma display in each room and voice control replacing keyboard and mouse. If I live long enough to see it I will be surprised."
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'First steps'
    hostname: 82.153.26.195
    created: '1181638767'
    body: "This post really got my juices flowing, learning of someone who's 'rolled their own' system in this way gives me great hope that a workable distributed PC could be achieved for the masses.  I imagine you had some difficulties and a lot of learning to get through to get this stuff working; and I would really love to hear more about it, such as how your boxes are setup to talk to each other and what each box does, even pics, perhaps posted onto your blog and linked back here.  Would be great for me to have a look through, but only if you can be bothered :o).  As I may have mentioned I'm writing a follow up detailing how I think the system should work from a user point of view, stuffed with a bit more technical detail, and it would be great to have the benefit of your experiences to refer to.\r\n\r\nYou are a pioneer sir and I salute you!"
-
    name: 'Anonymous visitor'
    mail: go.to@tesco.net
    subject: hypertransport
    hostname: 80.7.102.189
    created: '1184609058'
    body: "I'd wonder a while ago why no one has done this. Especially as home media systems started to emerge\r\n\r\nMy solution to those ungainly wires at the back is simple to have a protrusion from the top that slots into the bottom basically being a bus. Probably using removable cartridge style items that can also be pulled out to push in a nice top/bottom plate. A stack of interlocking bricks.\r\n\r\nMy plan was to make use of the AMD hyper transport intended to provide high communications between servers or extended the PCI bus up."
-
    name: JohnMc
    mail: john.mcginnis@tx.rr.com
    subject: 'Novel? Not hardly....'
    hostname: 72.190.96.105
    created: '1184776481'
    body: "First as a concept, yes its ok. But I have to tell you -- you ain't the first. The very idea you are promoting is Commodore64 write large for todays market. If you will recall, if you are old enough, is that you bought a component CPU/keyboard module from Commodore. The Commodore had IO code written to understand device level components. Add a hard drive, all the logic and the processing power for the drive was in the drive module. Want to dial out? You could buy a Modem and its supporting terminal software all built into the unit. You could string all these modules together with what would look like a SATA cable today. The idea has been around since the 1980's.\r\n\r\nFinally, up to a point I think this idea is heading in a direction opposite that of the market. I can for $200 buy a small sealed terminal like device with all the IO (parallel, serial, usb, etc) I could want. It boots a remote linux distro. All my apps reside external -- out on the network. \r\n\r\nThe other trend that will help you though is the idea of virtualization. Soon when most PC's have 4-8 uC's in them, multiple virutal OS's will be the norm. At that point the view from the end user is that any OS they use is nothing more than a file instance on a drive or network somewhere. When the Host layer is very thin indeed then you will have achieved the file centric OS model to some degree. "
-
    name: feranick@hotmail.com
    mail: feranick@hotmail.com
    subject: 'one question?'
    hostname: 69.236.77.224
    created: '1184830980'
    body: 'Laptops? All this works great for desktops, but how do you combine this effort with the needs of having small mobile and power efficient devices? '
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Heh, yeah the good old'
    hostname: 82.153.26.195
    created: '1184848038'
    body: "Heh, yeah the good old Commodore64, what a joy.  Being quite young and totally skint at the time, I never had the joy of attaching any peripherals to my base unit (aside from the included tape player and a joystick) so I've never experienced this particular facet, but it's great to know it worked like that!  On the subject of being first I'm sure you're quite right about that, Asus posted a mock-up of a similar system a few months before my article, Sun's JINI has been around a while, also taking a device-centric approach; going back even further to the 60s and 70s you've got the Modular One system (http://www.4links.co.uk/The-Origins-of-SpaceWire-colour.pdf), a mini-computer built up from smaller modules.  The idea certainly isn't new, and not particularly feasible for desktop systems up until recently.  What makes the idea important now (at least in my opinion) is the huge tide of connectible devices already available, along with the predicted surge of new devices in the near future; if like today they all go their own way with their own protocol and hardware interconnect things are gonna get incredibly messy.  Couple this with the already massive interoperability problems that exist today, particular for software running on 'standard' desktops (WinLinMac) all cramped in a single box and interfering with one another in largely unpredictable ways; and the dozens of different ways software and hardware can talk to each other (again, causing unpredictable interference with other hardware and software), and the need for a simple, clean, STANDARD way of connecting our hardware and software becomes clear.\r\n\r\nOn your comment regarding thin-terminals, with apps out on the network; there's nothing in this design (distributed hardware) that precludes such a setup.  Remember the idea is that a user can build (or buy) the computer they want; if you're blind you probably won't want a graphics device, if you prefer to work from a thin-terminal over the wire you can do that too.  All 'my design' is stipulating is that the devices and software involved should speak to each other in a 'common tongue', what those particular devices and software actually do, and how they work internally, is up to the device vendor.  I wrote a bit about using a modified version of HTTP for inter-device/application communication at (http://roleyology.blogspot.com/2007/06/distributed-desktops-part-six-protocol.html)that discusses this particular topic.  I've also been having words at (http://www.linuxsucks.org/topic/17035/1/Main/Time-for-an-OS-group-hug.html), if you can make it through this epic thread (long posts, bit of trolling, bit of arguing) there's more detail as well as some arguments about specific issues.  The fact that apps are external, out on the network, in this model works well with the idea of distributed hardware, and the idea of being able to reference anything (hardware features, applications, files) using the URI mechanism (or any mechanism that could be agreed upon) would be a major and compelling step in interoperability.\r\n\r\nVirtualisation (also discussed on the thread at linuxsucks.org) could be a useful tool for device vendors, one of the issues discussed involves reconfiguring your machine on the fly, for instance only running your audio and storage device for playing music without having the rest of the PC running.  Virtualisation would allow device vendors an easy way to switch configurations of a device to provide this kind of functionality.  Whether a particular device vendor used this approach or not would of course be up to them, for some devices it may be better to switch configurations for whatever OS is running inside the device, rather than switch to another Virtual OS within the device."
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'As far as I''m concerned a'
    hostname: 82.153.26.195
    created: '1184849557'
    body: "As far as I'm concerned a laptop is just a PC with tighter integration and a different shape.  Everything I've said in the article regarding desktops is equally applicable to laptops.  Remember that it's now possible to buy a complete PC that's only a couple of inches square, so building a series of devices to fit within a laptop isn't much of a stretch, in fact a lot of laptops are now built out of 'modular' components (each in their own box) already.  Two main concerns with laptops are of course energy efficiency and weight.  In terms of energy efficiency the arguments I applied in the article still stand for laptops; the fact that each device has its own CPU and 'network' connect do mean that individually they will consume more power than a 'naked' device, but remember in the modular system the devices could be powered down more intelligently and independently, and there isn't a single large parentboard/CPU in this design, another factor that may reduce overall power consumption.  Hard to tell one way or the other whether *overall* power efficiency would be better or worse, experimentation would be needed to verify that, but personally I'd favour the ability to power down the majority of my machine if those parts weren't in use.  Weight is a sticky issue, I certainly imagine a laptop built from distributed devices would weigh in much heavier than the equivalent integrated ones we get now; aside from filling the modules with helium this may be a tricky one to fix, though given current rates of miniaturisation (the 2inch square PC I mentioned above) I'm sure a solution could be found.\r\n\r\nIf laptops did follow a similar pattern to the desktop in this case it would be great if the components were shareable between them, such as unplugging a storage unit from your desktop and sticking it into your laptop, and also for the laptop (and all its devices) to integrate with the desktop when docked or in range.  This is part of the 'lonely device' problem that I think a standardised distributed system would help with; I've got a PC, DVD player, PS2 and TV, some connect to each other in a standard way, others have to be co-erced; if they all used the same interconnect and the same protocol to talk there'd be no reason why your PS 2 couldn't make use of processing cycles on your PC and vice-versa (or DVD or any other suitable device).  There are several connectors on the back of a TV, SCART, VGA, HDMI; personally I'd much prefer it if my TV plugged directly into a 'network' of my other devices, so that apps and other devices could just stream data over one interconnect/protocol, I'd like my DVD player, laptop, any device I purchase to work this way, things would just be so much easier if the big players worked on such a standard."
-
    name: 'Matthew Roley'
    mail: ''
    subject: Linuxsucks.org
    hostname: 82.153.26.195
    created: '1184849781'
    body: "For anyone who's interested, I've been discussing the article at\r\n\r\nhttp://www.linuxsucks.org/topic/17035/1/Main/Time-for-an-OS-group-hug.html\r\n\r\nSome trolling, arguing and a few VERY long posts (my fault, sorry).\r\n\r\n"
-
    name: Johann
    mail: santos.johann@gmail.com
    subject: Novatium
    hostname: 58.69.83.182
    created: '1185095383'
    body: "India is a paradox. You have a fast growing technology sector with a vast majority of the population still wallowing in poverty. They can build nuclear bombs but millions are still unable to feed themselves regularly and have to resort to selling their organs in Europe and America.\r\n\r\nAs part of the effort to bridge the digital divide, Novatium, working parallel with John Negroponte's $100 PC initiative has developed their own NetPC appliance at $70 without the monitor. The thin client type apparatus requires a fairly fast Internet connection to fully optimize its use. An alternative product they manufacture--NetTV--can receive cable signals and will provide PVR functions together with desktop computing. In essence you'd need a central server to use the NetPC or a software service provided through the user's Internet service provider. Device expansion is provided via USB 2.0 ports. The appliance itself consists of components normally used in cellular telephones.\r\n\r\nThe system has been used in depressed areas where access to PCs has been difficult because of the cost of the standard desktop. It has also been deployed as a smart home solution with emphasis on home entertainment. Aside from high-end, processor intensive apps, the system will allow you to do anything a normal desktop can. For a lot of people, this is enough.\r\n\r\nI imagine this type of paradigm--along with your component-based PC idea--would make up the next generation of computer systems."
-
    name: Conficio+
    mail: KajKandler@conficio.com
    subject: 'Plan-9 from Bell Labs a distributed OS'
    hostname: 71.233.234.9
    created: '1185885124'
    body: "Hi there,\r\nI believe the system design is not new from a software/OS standpoint.Bell Labs, the cradle of Unix (and in extension Linux) has developed Plan-9 a distributed OS (http://plan9.bell-labs.com/plan9/)\r\n\r\nAnother crux is the multitude of cables and power supplies. For this to work you'd need a bus to distribute power (in a format the is usable for the components) and the communication. Otherwise you have so many power supplies, each with its own inefficiency and heat production. In addition the extra boxes do not make this a very green concept.\r\n\r\nHowever, I'd like to see innovation in terms of distribution. For example why do I need a set of cables to connect a monitor, keyboard, device, etc. with the main pc box. A simple combination cable should be very helpful and allow me to daisy chain. In other words, give me a USB hub in any display.\r\n\r\nGo a little further in design and tell me why the graphic card is in the PC, instead of in the Monitor. I think we need a redesign of the processing/visualization interface, in order to match graphic card and monitor abilities more closely. This means lots of cost savings, because the graphic card does not have to support all kinds of resolutions, that the monitor can't display in the first place. It should also cut down on driver development cost.\r\n\r\nIn todays world the interface should be at the level of drawing vectors, rendering font and streaming images (and for the gamers some scene rendering). Drawing vectors and font is low bandwith. Streaming images is medium (after all any TV can do it) and I guess scene rendering can be handled at a decent bandwith level as well.\r\n\r\nK&lt;0&gt;"
-
    name: 'Matthew Roley'
    mail: ''
    subject: "Hi Conficio+\nA few different"
    hostname: 82.153.26.195
    created: '1185975645'
    body: "Hi Conficio+\r\n\r\nA few different topics here so I'll reply to each separately...\r\n\r\n<cite>\r\nI believe the system design is not new from a software/OS standpoint.Bell Labs, the cradle of Unix (and in extension Linux) has developed Plan-9 a distributed OS (http://plan9.bell-labs.com/plan9/)\r\n</cite>\r\n\r\nIt's quite funny, about 3 years ago I downloaded Plan9 and had a play with it, long before I even had the idea of writing this article.  I didn't read any of the documentation and had no idea it was a distributed OS until your comment, guess this aspect isn't readily seen if you're running it on a single PC as I was.  Didn't consider it a viable OS alternative at the time so ended up removing it, but after reading your comment I may give it another try just to see how closely it matches what I've been writing about.\r\n\r\nBased on Plan9's documentation I can see a number of similarities.  The basic design principles; consistent naming of resources, as well as a standardised protocol for their access, are strikingly similar, but then, they should be, these two steps are pretty much mandatory if you want a simple distributed system.  How these principles are implemented however, differs to a large extent between what I'm proposing and what Bell Labs have achieved with Plan9.  \r\nFirstly, while Plan9 has a standard messaging protocol (9P) there is no assumption about the underlying network (other than it will be unreliable).  To this end, a reliable transport protocol needs to be added (in the case of Plan9 they use IL, again, a protocol designed by the Plan9 people, designed to serve a similar purpose to TCP but without the overhead).  The upshot of this is that Plan9's networking protocol can work over any transport (Ether, USB etc) and so the 'devices' in Plan9 can be connected together by a variety of cables while still ensuring reliable transport.  In contrast, what I'm proposing is not only a standard networking protocol (like 9P) but also a standard network connection and transport.  The main reason for this is simplicity, rather than having a multitude of connectors, and the necessity of having the correct ports on the machines to be networked (and that means extra software inside the boxes to account for all possible 'network' hardware, ethernet drivers, TCP, Plan9's IL, USB etc), there should be a single (read idiot proof) way to connect devices together, ideally with as little impact on the host systems as possible in terms of required 'drivers'.  One example I cite is Infiniband, this technology has high enough bandwidth that even uncompressed video could be shunted about with relative ease, low enough latency to be usable, and with reliable transport provided at the hardware level rather than through the addition of a transport protocol.  If USB could somehow achieve the same performance as Infiniband it would be an even better choice, as USB incorporates power transfer too.  A second important difference is in the definition of distributed for these two systems.  I may be wrong about this but the impression I get from the Plan9 docs is that it is more a centralised time-sharing system, users have a terminal or workstation through which they interact, but all the work takes place on those centralised CPUs, in a way similar to the standard Unix setups you tend to see in research institutes and academia.  To this end all machines (devices) in a Plan9 distributed computer all need to be running the Plan9 kernel.  Contrasting with what I've written, machines (devices) in the network can run any operating system internally, with the requirements being instead that the device must implement the network protocol AND the network hardware, but apart from that can run any software it wants internally that helps it do its job.  For the actual protocol I also consider something such as HTTP more viable than a new protocol, see (http://www.linuxsucks.org/topic/17836/1/Main/re-Time-for-an-OS-group-hug.html), for more details, quite a bit of preamble in this post, but about halfway down there's a more comprehensive description of how I see the system working.  HTTP may seem like an odd choice for the transport protocol, but in combination with the right networking (i.e. something like Infiniband) I believe it would expose great power between devices while still being relatively simple both to implement and use, HTTP also gives the advantage of combining resource location and namespacing (through URLs) with the networking protocol as well as being already familiar to a large number of developers and users.  Also note in that post the simplicity of the file system, this is another necessary step I consider important, and is something that in my opinion all current systems have a problem with.  Plan9 solves this by using namespaces to restrict a users view of resources to only those that are currently relevant, in contrast with what I'm proposing where resources are hidden in the devices and the URLs exposed by the device signify resources available to users (if you can't see the difference here bear in mind that manipulating the users namespaced resources requires work on the part of the kernel, whereas using URLs to access internal device functions does not).  Also note in the file tree I describe how each device has management and configuration URLs; apart from providing simple, likely HTML based configuration screens for the device these URLs would also allow for direct access to the underlying device in a similar way to telnet or SSH, for if the user does need to get at the underlying operating system.\r\n\r\n<cite>\r\nAnother crux is the multitude of cables and power supplies. For this to work you'd need a bus to distribute power (in a format the is usable for the components) and the communication. Otherwise you have so many power supplies, each with its own inefficiency and heat production. In addition the extra boxes do not make this a very green concept.\r\n</cite>\r\n\r\nYes, this is potentially a major stumbling block as mentioned in the article, and is a problem with any distributed system (Plan9 included), in fact, cabling is a big problem in current PC system, there are far too many plugs and cables even now (though of course a distributed system would definitely be worse in this respect).  Ideally power should be transferred through devices using the same cable as networking (a la USB) though it may prove more difficult to incorporate this into a standard such as Infiniband.  Pass through power is also another option, though of course this doesn't alleviate the cables.  Wireless is yet another option for both networking and power (there have been recent demonstrations of wireless power transfer).  I would see such a system using both wired and wireless transfer, which possibly further exacerbates the cabling and power problems, and wireless has a long way to go before it could fulfill the latency/bandwidth requirements of a distributed system as I describe.  This is another reason (apart from greater simplicity for the user) why we absolutely need to standardise a networking/power interconnect for devices, both wired and wireless, not only to clean up the cables, but to make it trivial for users to plug things into each other (by far the most important factor in my opinion).  On the matter of power, remember that these devices will generally have low power requirements individually, as well as being more cleanly detachable from the system, it may be possible that overall power usage is reduced on such systems, we'll never know until one is built.\r\n\r\n<cite>\r\nHowever, I'd like to see innovation in terms of distribution. For example why do I need a set of cables to connect a monitor, keyboard, device, etc. with the main pc box. A simple combination cable should be very helpful and allow me to daisy chain. In other words, give me a USB hub in any display.\r\n</cite>\r\n\r\nYep, there is in my view too definitely a need for simpler and easier ways to connect devices, apart from external devices that all have differing connectors the internal devices such as graphics cards have all the problems I describe in the article.  Not sure about a combination cable, while it could be useful for a conventional PC it would introduce great inflexibility into a distributed system as I describe it, what if the user is blind for intstance and doesn't have a mouse, graphics device or monitor, that combination cable is gonna start looking pretty messy.\r\n\r\n<cite>\r\nGo a little further in design and tell me why the graphic card is in the PC, instead of in the Monitor. I think we need a redesign of the processing/visualization interface, in order to match graphic card and monitor abilities more closely. This means lots of cost savings, because the graphic card does not have to support all kinds of resolutions, that the monitor can't display in the first place. It should also cut down on driver development cost.\r\n</cite>\r\n<cite>\r\nIn todays world the interface should be at the level of drawing vectors, rendering font and streaming images (and for the gamers some scene rendering). Drawing vectors and font is low bandwith. Streaming images is medium (after all any TV can do it) and I guess scene rendering can be handled at a decent bandwith level as well.\r\n</cite>\r\n\r\nThis is one of those grey areas.  While having a graphics card in the monitor is ostensibly a logical and good idea, and provides several advantages as you describe, there are several disadvantages.  Firstly, what happens when the graphics card is no longer powerful enough for the latest games, a complete monitor replacement is necessary, which sort of eliminates the cost savings for the user.  Another option I'd like available for a distributed system is also multiple graphics devices, allowing for redundancy and concurrent (and hence faster) usage.  If the graphics devices are in the monitor this obviously becomes problematic.\r\n\r\nOne possible solution I discuss at linuxsucks.org, which matches what you say but in a slightly different way, is to have a 'screen manager' within the monitor.  Really this is what you describe, a graphics device in the monitor, matched to the capabilities of the monitor.  However, this graphics device does not do general graphical operations in the same way a conventional graphics card does, and instead focuses on composition.  Applications on the system send their bitmaps to the monitor, where the internal graphics card composites them for display.  The applications themselves could work directly with bitmaps, or use other parts of the system (such as an accelerated graphics device providing vector and font functionality) to generate bitmaps on their behalf.  This would allow for additional 3d graphics devices to be added to the system, they simply send frames as they are created to the monitor, which composites them into an overall display, you could have several 3d devices generating bitmap data for a single 'window', or each 3d device could be generating bitmaps for different windows.  Sending lots of bitmaps around does of course require a good amount of bandwidth both on the network and inside the devices, so this may not be viable even if the networking (such as Infiniband) has sufficient bandwidth to cope.  If it could work this way there'd be a great amount of flexibility exposed, but again there would be a 'bottleneck' in terms of the graphic card within the monitor, so it may be wise to 'keep it distributed', even in the case of a composition device, so that it can be upgraded or replaced if need be without impacting the rest of the system. \r\n\r\n\r\n\r\n\r\n\r\n"
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'NetTV is one of those ideas'
    hostname: 82.153.26.195
    created: '1185976890'
    body: "NetTV is one of those ideas that fits in nicely with what I'm proposing, with a user's computer consisting solely of the devices and software needed to do its job.  As you say a device providing for standard home use and entertainment would be enough for many users, in effect meaning they'd only need one device, but in a distributed system more hardware can be added according to the needs of the individual user, so a distributed, standardly (couldn't think of a better word there :) connected paradigm can serve an entire spectrum of users with entirely different computing needs, while still retaining the very important characteristics of simplicity in terms of connecting devices/software and having them talk to each other in a standard way.\r\n\r\nThe idea of using components from mobiles is particularly interesting; I discuss in my article the ability to switch configurations so that if you're for example just playing music you can reconfigure your machine on the fly so only the audio and storage (where your music resides, either on an optical drive or storage device) are powered up and active.  Having a small display on such devices would be extremely useful, and the low power screens used on mobiles are ideal for this kind of function.  Thinking of the millions of discarded mobiles every year it would be fantastic if at least part of those devices could be recycled for use this way, and devices having their own mini display like this would make them more portable and viable as standalone appliances, increasing the flexibility of the overall system into which they're connected.  This brings me to another point I mentioned in the article, because the devices are in effect appliances in their own box (as opposed to naked expansion cards) a device one user considers 'obsolete' in the richer western countries would still be of enormous value to those in poorer or deprived areas, and the fact that such devices would have a standardised connector means such discarded devices could still be useful to say, a user in India, and could be attached to his/her system without difficulty.  In the normal course of things an obsolete naked expansion device would probably end up in the bin, but a boxed connectible device could be shipped off to someone who can make use of it.\r\n\r\n"
-
    name: Johann
    mail: santos.johann@gmail.com
    subject: Modularization
    hostname: 58.69.83.101
    created: '1186300949'
    body: "With respect to modularization, the idea of using alternative components for the devices that would be plugged into the system, I mentioned before that NetPC and NetTv use cellular phone technology. This allows both devices to maintain a smaller footprint on the desktop and enables a fan-less infrastructure. The power requirements are dramatically reduced as well.\r\n\r\nGoing beyond mobile phones, other mobile devices--MP3 players, MP4 players, laptops--all consume less power while delivering the computing and entertainment needs that their users expect. A laptop running on AC power consumes approximately 60-90w as compared to a full desktop that can use as much as 400w.\r\n\r\nFollowing the paradigm of familiar home entertainment systems it is possible to build a modular component PC. A stereo for example will play back CDs but the sound will be much more enjoyable with the addition of amplifiers, tweeters and sub-woofers. In the same way, the distributed PC could be built around a basic system--think something similar to Apple's Mac Mini--which can be expanded as needed. A graphics module to enhance the display, a network storage device, audio peripherals, etc. Each with their own processing capability (built on cellular components) to distribute the processing requirements of the applications that the user will run. All with a standard connector--USB.\r\n\r\nBottom-line--it is possible even now to start building the distributed component PC with a little tweaking from off-the-shelf parts."
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'As mentioned in the article,'
    hostname: 82.153.26.195
    created: '1186402063'
    body: "As mentioned in the article, power management would be a critical part of the distributed system as I see it; with the addition of potentially limitless peripherals to a system, each having their own processor and memory, minimised power usage is essential for each individual component.  Being able to power-state-change components more cleanly is an advantage, but each device would need to strike a balance between the performance required to do its job and the power requirements of achieving that performance.  For many devices, it is likely that extremely low MHz processors, as used in mobiles, would be sufficient to allow the device to do its job, and with most of the system employing such devices it is possible that power consumption equivalent to a laptop could be achieved.  There may however, be devices requiring a bit more oomph, this is why I think it would be important to allow device vendors to choose hardware appropriate for their device, balancing power consumption against the increased performance of the device.  With each device in its own box communicating over a protocol hardware vendors would indeed be able to pick whatever hardware is appropriate for their device, whether it be a 33MHz RISC processor or a 3GHz dual-core monster.\r\n\r\nI'm not sure about the Mac Mini as a good example or basis for a distributed system (at least not in the way I describe in the article).  The Mac Mini is essentially a small form factor PC, and while it has a whole heap of expansion options in terms of USB, Firewire and Ethernet it still suffers from the problems of integrated systems as I describe in the article.  For starters, the real hardware still resides in the main case, meaning upgrading memory and components such as the graphics card still require opening the case (which in this case is actually more difficult than opening a standard PC).  Additionally, there's still the problem of drivers for devices having to reside on the hard drive of the main box, while this doesn't present much of a problem for the external peripherals it is a problem for the devices in the case as I describe in the article.  With regards to expansion and the use of USB - I really like USB as a connection standard, it's got pretty much the most usable connector available and it handles both data and power transfer.  For the kind of system I'm thinking of however, it would not be adequate (at least not in its current revision) - firstly, USB devices are far too dependent on the host system (i.e. a conventional PC) to be viable as standalone appliances that could be plugged together, the host system is effectively a bottleneck and a single point of failure and all USB devices have to share bandwidth on the bus (as opposed to switched systems like Infiniband, where each node gets full-speed full-duplex transfer rates).  Additionally, while the bandwidth available on a Hi-Speed USB connector is reasonable (480Mbps, translating to about 60MB/s in theory but only roughly 30MB/s in practice) it is certainly not enough for transferring more intensive graphical data, particularly because of the shared bandwidth with the other USB devices, and AFAIK the latency window of USB is measured in milliseconds which I think is too high for a distributed system in general (really need latencies in the microseconds to get respectable response).  For the low-end systems you describe it would certainly be enough, but remember that I'm trying to think of a system with a standard interconnect and protocol that could be used for any device or system, so building low-end systems using say USB and high-end systems using say InfiniBand would defeat this objective.\r\n\r\nFor your bottom line I definitely agree - it is eminently possible to build a distributed component PC now through tweaking off-the-shelf parts.  Tinker who commented above has achieved his own system using ethernet connected boxes.  There are literally infinite ways to do it, but when you consider interoperability with ANY other device, and the requirements of keeping up with the demands of new and as yet unknown devices, as well as the need to provide performance for those who need it (thinking of gamers here) the number of correct ways to do it gets considerably smaller.  Hence the need for a standard protocol and device interconnect, along with a shift from integrated PCs (with all drivers and applications, and the meat of the hardware, locked in a single box) to a TRUE distributed system where each device has its own software, is independent but can communicate with other devices easily because of a standardised interconnect.\r\n\r\n"
-
    name: 'Dave Guard'
    mail: ''
    subject: 'Matt this could be what you were after...'
    hostname: 190.184.55.214
    created: '1194312663'
    body: "Check this out: \r\n\r\nhttp://www.linuxdevices.com/news/NS3871478989.html"
-
    name: 'Matthew Roley'
    mail: ''
    subject: 'Thanks Dave'
    hostname: 82.2.118.20
    created: '1194341276'
    body: 'Looks very interesting indeed!  Will definitely be keeping an eye on how this develops.'
-
    name: 'Jeroen van Splunder'
    mail: ''
    subject: 'Comment removed by user.'
    hostname: 213.51.200.114
    created: '1310921608'
    body: 'Comment removed by user.'
